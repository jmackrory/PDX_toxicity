{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Toxicity in Wikipedia Comments\n",
    "\n",
    "This is a parallel work to any work on the wikipedia toxicity data on the same\n",
    "topic.  This data has not been cleaned yet, and has not had multiple categories introduced yet.  However it is presented free from bias, for people to play with.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk as nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 128M\r\n",
      "-rw-rw-r-- 1 jonathan jonathan  18M Jan 14 10:28 boardgame-frequent-user-comments.csv\r\n",
      "-rw-rw-r-- 1 jonathan jonathan  75M Jan 14 10:27 toxicity_annotated_comments.tsv\r\n",
      "-rw-rw-r-- 1 jonathan jonathan 692K Jan  7 14:27 toxicity_annotated_comments_unanimous.tsv\r\n",
      "-rw-rw-r-- 1 jonathan jonathan  35M Jan 14 10:27 toxicity_annotations.tsv\r\n",
      "-rw-rw-r-- 1 jonathan jonathan 775K Jan  7 14:27 toxicity_annotations_unanimous.tsv\r\n",
      "-rw-rw-r-- 1 jonathan jonathan  93K Jan  7 14:27 toxicity_worker_demographics.tsv\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3582, 7) (35152, 4)\n"
     ]
    }
   ],
   "source": [
    "df_com = pd.read_csv('data/toxicity_annotated_comments_unanimous.tsv',sep='\\t')\n",
    "df_rate = pd.read_csv('data/toxicity_annotations_unanimous.tsv',sep='\\t')\n",
    "#make rev_id an integer\n",
    "df_com['rev_id']=df_com['rev_id'].astype(int)\n",
    "df_rate['rev_id']=df_rate['rev_id'].astype(int)\n",
    "\n",
    "#reindex \n",
    "#df_com.index=df_com['rev_id']\n",
    "#df_rate.index=df_rate['rev_id']\n",
    "print(df_com.shape, df_rate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#make a new column in df_com with array of worker_ids, and toxicity\n",
    "df_com['scores']=None\n",
    "\n",
    "#since 'rev_id' is sorted, can take first difference, and find where\n",
    "#there are changes.  Those set the boundaries for changes.\n",
    "#Need to also append final index.\n",
    "change_indices=df_rate.index[df_rate['rev_id'].diff()!=0].values\n",
    "change_indices=np.append(change_indices,len(df_rate))\n",
    "\n",
    "for i in range(len(change_indices)-1):\n",
    "    ind0 = change_indices[i]\n",
    "    ind1 = change_indices[i+1]\n",
    "    d0=df_rate.iloc[ind0:ind1]\n",
    "    scores=d0[['worker_id','toxicity_score']]\n",
    "    #pass it a list so it can be set as an entry.\n",
    "    #accessing later will require score[0] idiocy to get at list.\n",
    "    df_com.loc[i,'scores']=[scores.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_mean(score_list):\n",
    "    \"\"\"score_mean\n",
    "    Compute mean of toxicity scores for input array.\n",
    "    Array is first (and only) element in the input list.\n",
    "    Compute mean running down the rows.  Could be updated to include weighted sum of weights\n",
    "    \"\"\"\n",
    "    s_arr=score_list[0]\n",
    "    s = np.mean(s_arr[:,1])\n",
    "    return s\n",
    "\n",
    "score_mean(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_com['mean_toxic']=df_com['scores'].apply(score_mean)\n",
    "df_com['toxic']=df_com['mean_toxic']!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_com['toxic'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rev_id\n527004       0.0\n603474       0.0\n808576       0.0\n986363       0.0\n1433843      0.0\n1988528      0.0\n1988988      0.0\n2078042      0.0\n2747887      0.0\n2850252      0.0\n3072376      0.0\n3833612      0.0\n4402645      0.0\n5501854      0.0\n5996506      0.0\n6117068      0.0\n6569572      0.0\n7005403      0.0\n7278042      0.0\n7482390      0.0\n8078390      0.0\n8190858      0.0\n8355464      0.0\n8384537      1.0\n8410988      0.0\n8470953      0.0\n8486458      0.0\n8898541      0.0\n9125825      0.0\n9180326      0.0\n            ... \n693072891    0.0\n693172874    0.0\n693258130    0.0\n693591656    0.0\n693603090    0.0\n693758023    0.0\n694377826    0.0\n694418527    0.0\n694524243    0.0\n695346026    0.0\n695411224    0.0\n695437195    0.0\n695519219    0.0\n695673624    0.0\n695755011    0.0\n696040084    0.0\n696130208    0.0\n696215805    0.0\n696223206    0.0\n696721125    0.0\n696792920    0.0\n696803203    0.0\n696827903    0.0\n696920504   -1.0\n697089785    0.0\n697514711    0.0\n697541689    0.0\n697796623    0.0\n697971737    0.0\n699660419   -1.0\nName: toxicity_score, Length: 3582, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rate.groupby('rev_id')['toxicity_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#can combine the dataframes together by extracting all reviewer ids, and scores for each "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Looking at the comments data, we'll need to clean the data quite a bit (lots of newlines, weird characters).\n",
    "\n",
    "My rough plan is to build up a lexicon, tokenize that data, and try to build a Naive Bayes model.  (Maybe later a Recurrent Neural network model?)\n",
    "\n",
    "Other Analysis possibilities:\n",
    "* Support Vector Machine\n",
    "    - the other big architecture, less popular now?\n",
    "* Recurrent Neural Network\n",
    "    - Build up word embeddings (word2vec), or just use the pretrained ones.\n",
    "* Naive Bayes\n",
    "    - can find most important words in spam\n",
    "    - simple, easy to understand baseline.\n",
    "* Latent Factor Analysis \n",
    "    - maybe useful prelude for building up embeddings. \n",
    "    \n",
    "Cleaning:\n",
    "* Tokenize (convert words to indices)\n",
    "* Clean data : How to remove newlines (search/replace: NEWLINE with '')\n",
    "* Stemming words\n",
    "* Balancing data set\n",
    "* Match up comments, and review scores\n",
    "\n",
    "\n",
    "* Search for gibberish words (make a new \"feature\" for badly spelled comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#borrowing from http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect=CountVectorizer()\n",
    "X_train_counts=count_vect.fit_transform(df_com['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3582, 11554)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "init_explore.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
