{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Toxicity in Wikipedia Comments\n",
    "\n",
    "This is a parallel work to any work on the wikipedia toxicity data on the same\n",
    "topic.  This data has not been cleaned yet, and has not had multiple categories introduced yet.  However it is presented free from bias, for people to play with.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Looking at the comments data, we'll need to clean the data quite a bit (lots of newlines, weird characters).\n",
    "\n",
    "My rough plan is to build up a lexicon, tokenize that data, and try to build a Naive Bayes model.  (Maybe later a Recurrent Neural network model?)\n",
    "\n",
    "Other Analysis possibilities:\n",
    "* Support Vector Machine\n",
    "    - the other big architecture, less popular now?\n",
    "* Recurrent Neural Network\n",
    "    - Build up word embeddings (word2vec), or just use the pretrained ones.\n",
    "* Naive Bayes\n",
    "    - can find most important words in spam\n",
    "    - simple, easy to understand baseline.\n",
    "* Latent Factor Analysis \n",
    "    - maybe useful prelude or alternative for building up embeddings.\n",
    "    \n",
    "Cleaning:\n",
    "* Clean data : How to remove newlines (search/replace: NEWLINE with '')\n",
    "* Tokenize (convert words to indices)\n",
    "* Stemming words\n",
    "* Balancing data set\n",
    "* Match up comments, and review scores\n",
    "* Search for gibberish words (make a new \"feature\" for badly spelled comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk as nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159686, 7) (1598289, 4)\n"
     ]
    }
   ],
   "source": [
    "#df_com = pd.read_csv('data/toxicity_annotated_comments_unanimous.tsv',sep='\\t')\n",
    "#df_rate = pd.read_csv('data/toxicity_annotations_unanimous.tsv',sep='\\t')\n",
    "df_com = pd.read_csv('data/toxicity_annotated_comments.tsv',sep='\\t')\n",
    "df_rate = pd.read_csv('data/toxicity_annotations.tsv',sep='\\t')\n",
    "\n",
    "#make rev_id an integer\n",
    "df_com['rev_id']=df_com['rev_id'].astype(int)\n",
    "df_rate['rev_id']=df_rate['rev_id'].astype(int)\n",
    "\n",
    "#reindex \n",
    "#df_com.index=df_com['rev_id']\n",
    "#df_rate.index=df_rate['rev_id']\n",
    "print(df_com.shape, df_rate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#make a new column in df_com with array of worker_ids, and toxicity\n",
    "df_com['scores']=None\n",
    "\n",
    "#since 'rev_id' is sorted, can take first difference, and find where\n",
    "#there are changes.  Those set the boundaries for changes.\n",
    "#Need to also append final index.\n",
    "change_indices=df_rate.index[df_rate['rev_id'].diff()!=0].values\n",
    "\n",
    "#use numpy split instead.\n",
    "arr=df_rate[['worker_id','toxicity_score']].values\n",
    "split_arr=np.split(arr,change_indices)\n",
    "#drop first index as empty\n",
    "split_arr.pop(0)\n",
    "df_com['scores']=split_arr\n",
    "#change_indices=np.append(change_indices,len(df_rate))\n",
    "# for i in range(len(change_indices)-1):\n",
    "#     ind0 = change_indices[i]\n",
    "#     ind1 = change_indices[i+1]\n",
    "#     d0=df_rate.iloc[ind0:ind1]\n",
    "#     scores=d0[['worker_id','toxicity_score']]\n",
    "#     #pass it a list so it can be set as an entry.\n",
    "#     #accessing later will require score[0] idiocy to get at list.\n",
    "#     df_com.loc[i,'scores']=[scores.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def score_mean(score_list):\n",
    "    \"\"\"score_mean\n",
    "    Compute mean of toxicity scores for input array.\n",
    "    Array is first (and only) element in the input list.\n",
    "    Compute mean running down the rows.  Could be updated to include weighted sum of weights\n",
    "    \"\"\"\n",
    "    s = np.mean(score_list[:,1])\n",
    "    return s\n",
    "\n",
    "def score_median(score_list):\n",
    "    \"\"\"score_median\n",
    "    Compute median of toxicity scores for input array.\n",
    "    Array is first (and only) element in the input list.\n",
    "    Compute mean running down the rows.  Could be updated to include weighted sum of weights\n",
    "    \"\"\"\n",
    "    s = np.median(score_list[:,1])\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_com['mean_toxic']=df_com['scores'].apply(score_mean)\n",
    "df_com['median_toxic']=df_com['scores'].apply(score_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments: 159686. Toxic comments: 1610. Toxic Fraction: 0.01008228648723119\n"
     ]
    }
   ],
   "source": [
    "df_com['toxic']= (df_com['median_toxic']<=-2)\n",
    "Ntoxic=df_com['toxic'].sum()\n",
    "Ntot=len(df_com)\n",
    "print(\"Total comments: {}. Toxic comments: {}. Toxic Fraction: {}\".format(Ntot,Ntoxic,Ntoxic/Ntot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#can combine the dataframes together by extracting all reviewer ids, and scores for each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#cleaning the data\n",
    "#Can use pandas built in str functionality with regex to eliminate\n",
    "\n",
    "#maybe also dates?\n",
    "def clean_up(comments):\n",
    "    com_clean=comments.str.replace('NEWLINE_TOKEN',' ')\n",
    "    com_clean=com_clean.str.replace('TAB_TOKEN',' ')    \n",
    "    #Remove HTML trash, via non-greedy replacing anything between backticks\n",
    "    com_clean=com_clean.str.replace(\"style=\\`\\`.*?\\`\\`\",' ')\n",
    "    com_clean=com_clean.str.replace(\"class=\\`\\`.*?\\`\\`\",' ')\n",
    "    com_clean=com_clean.str.replace(\"width=\\`\\`.*?\\`\\`\",' ')\n",
    "    com_clean=com_clean.str.replace(\"align=\\`\\`.*?\\`\\`\",' ')\n",
    "    com_clean=com_clean.str.replace(\"cellpadding=\\`\\`.*?\\`\\`\",' ')\n",
    "    com_clean=com_clean.str.replace(\"cellspacing=\\`\\`.*?\\`\\`\",' ')\n",
    "    com_clean=com_clean.str.replace(\"rowspan=\\`\\`.*?\\`\\`\",' ')\n",
    "    com_clean=com_clean.str.replace(\"colspan=\\`\\`.*?\\`\\`\",' ')\n",
    "    #remove numbers\n",
    "    com_clean=com_clean.str.replace(\"[0-9]+\",' ')\n",
    "    #remove numbers\n",
    "    com_clean=com_clean.str.replace(\"_\",' ')\n",
    "    #remove symbols.    \n",
    "    com_clean=com_clean.str.replace(\"[\\[\\[\\{\\}=_:|\\(\\)\\\\\\/]+\\`\",' ')\n",
    "    #remove multiple spaces, replace with a single space\n",
    "    com_clean=com_clean.str.replace('\\\\s+',' ')\n",
    "\n",
    "    #remove symbols\n",
    "    return com_clean\n",
    "df_com['comment_clean']=clean_up(df_com['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95692"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separate off training_split\n",
    "train_msk=df_com['split']=='train'\n",
    "df_train=df_com[train_msk]\n",
    "(df_com['split']=='train').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95692, 125568)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#borrowing from http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "count_vect=CountVectorizer(stop_words='english',lowercase=True,strip_accents='unicode')\n",
    "X_train_counts=count_vect.fit_transform(df_train['comment_clean'])\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Checking the vectorizer and finding common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#get vocabulary dictionary\n",
    "voc_dict=count_vect.vocabulary_\n",
    "#make a dataframe, with entries as rows\n",
    "voc_df=pd.DataFrame.from_dict(voc_dict,orient='index')\n",
    "#sort by row entry value, and then use that as the index for the counts.\n",
    "voc_df1=voc_df.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29143\nName: dick, dtype: int64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_df1.iloc[29143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "X_cond= pw_tox*ptox/(pw_tox*ptox + pw_cln*(1-ptox))\n",
    "word_mat=np.array([X_train_counts.sum(axis=0),X_cond,pw_cln,pw_tox]).squeeze()\n",
    "word_df=pd.DataFrame(word_mat.T,columns=['count','pcond)','p_clean','p_toxic'],index=voc_df1.index)\n",
    "print(word_df.sort_values('pcond)',ascending=False,inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "xtot=X_train_counts.sum(axis=0).squeeze()\n",
    "#compare vectorized vs. naive counts to check mappings\n",
    "def check_vect(count_mat,comments,vocab,word):\n",
    "    \"\"\"check_vect(count_mat,comments,vocab,word)\n",
    "    Checks the counts/occurence of words between the count vectorizer,\n",
    "    and a naive 'contains' search.  Returns all the matching comments,\n",
    "    and any discrepencies.        \n",
    "    \"\"\"\n",
    "    ind=vocab.loc[word].values\n",
    "    xtot=count_mat.sum(axis=0)\n",
    "    vect_count=(xtot[0,ind])\n",
    "    #find comments with words\n",
    "    msk=(count_mat[:,ind]>0).toarray().squeeze()\n",
    "    #find comments via naive search\n",
    "    naive_msk=comments.str.contains('{}'.format(word),case=False)\n",
    "    naive_count=np.sum(naive_msk)\n",
    "    comments=comments[msk]\n",
    "    naive_comments=comments[naive_msk]\n",
    "    diff_comments=comments[msk!=naive_msk]\n",
    "    return vect_count,naive_count,comments,naive_comments,diff_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "vc,cc,com,ncom,dcom=check_vect(X_train_counts,df_train['comment_clean'],voc_df,'gay')\n",
    "#searching for 'fuck' gives a salutory lesson in why accent tripping is worthwhile, and a simple word filter will probably be circumvented.\n",
    "#does not account for leetspeak or rather: 13375|o3@|< (but who uses that these days?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vect: [[1866]], Naive: 638\n",
      "[588     ` Pro-Gay Bias? To be honest, I am not sure I entirely follow. What is exactly is meant by holdi...\n",
      "790     ` There is one other thing that just occured to me: an encyclopedia deals in facts, not in specu...\n",
      "871     ` Dante, I agree that it is the use of the word that constructs a POV. Of course, in a technical...\n",
      "1443    Stop editing it. I'm from Santa Clarita, I went to Saugus High School so I know that they are, i...\n",
      "1467     WHY ARE YOU SUCH A GAY NIGGER?!?! GOD DAMNDD... YOU ARE SUCH A GAY NIGGER. FUCK FUCK SHTAY AWAY...\n",
      "Name: comment_clean, dtype: object, 588     ` Pro-Gay Bias? To be honest, I am not sure I entirely follow. What is exactly is meant by holdi...\n",
      "790     ` There is one other thing that just occured to me: an encyclopedia deals in facts, not in specu...\n",
      "871     ` Dante, I agree that it is the use of the word that constructs a POV. Of course, in a technical...\n",
      "1443    Stop editing it. I'm from Santa Clarita, I went to Saugus High School so I know that they are, i...\n",
      "1467     WHY ARE YOU SUCH A GAY NIGGER?!?! GOD DAMNDD... YOU ARE SUCH A GAY NIGGER. FUCK FUCK SHTAY AWAY...\n",
      "Name: comment_clean, dtype: object]\n"
     ]
    }
   ],
   "source": [
    "#currently searching for \"jew\", a term that has clean connotations, but can be used as anti-semitic.\n",
    "print('Vect: {}, Naive: {}'.format(vc,cc))\n",
    "print([com.head(),ncom.head()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck count: 6179\n",
      "shit count: 1689\n",
      "cunt count: 619\n",
      "piss count: 151\n",
      "cocksucker count: 425\n",
      "dick count: 1022\n",
      "ass count: 1275\n",
      "nigger count: 1238\n"
     ]
    }
   ],
   "source": [
    "naughty_word=['fuck','shit','cunt','piss','cocksucker','dick','ass','nigger']\n",
    "word_counts=X_train_counts.sum(axis=0)\n",
    "for word in naughty_word:\n",
    "    try:\n",
    "        ind=count_vect.vocabulary_[word]\n",
    "        print(word,'count: {}'.format(word_counts[0,ind]))\n",
    "    except:\n",
    "        print(word,'not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "I noticed that there are very few obvious racist slurs in the unanimous data set. (lots of sexism, general hate)\n",
    "Weird sociological question on perception of toxicity of racism, perhaps by american reviewers?\n",
    "\n",
    "(searching for the n-word found these)\n",
    "Some ratings seem way off. e.g. the scores for comments 1467, 1657 include some -1s.\n",
    "Someone even thought 1918 was neutral!\n",
    "Wait, 2669 and 2670 are now identical comments. And some raters thought that 2670 was neutral too!  What the hell?!\n",
    "This suggests using the median toxicity score.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Naive Bayes\n",
    "\n",
    "I want to implement a Naive Bayes classifier as a baseline.  I've written my own version, which I will try to compare to\n",
    "scikit-learns version.  First up, my version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def cond_prob(X_counts,toxic,csmooth=1):\n",
    "    \"\"\"bayes_prob\n",
    "    X_counts - sparse matrix of counts of each word in a given message\n",
    "    toxic - whether word was toxic or not, with 0,1\n",
    "    \"\"\"\n",
    "    nrows,nwords=X_counts.shape\n",
    "    ptoxic = np.sum(toxic)/nrows\n",
    "    \n",
    "    toxic_mat=X_counts[toxic==1,:]\n",
    "    clean_mat=X_counts[toxic==0,:]\n",
    "    #sum across messages\n",
    "    nword_toxic=np.sum(toxic_mat,axis=0)\n",
    "    nword_clean=np.sum(clean_mat,axis=0)    \n",
    "\n",
    "    #estimate probability of word given toxicity by number of times\n",
    "    #that word occurs in toxic documents, divided by the total number of words\n",
    "    #in toxic documents\n",
    "    #Laplace/Lidstone smooth version\n",
    "    pword_toxic= (nword_toxic+csmooth) \\\n",
    "                / (np.sum(toxic_mat)+nwords*csmooth)\n",
    "\n",
    "    pword_clean= (nword_clean+csmooth) \\\n",
    "                /(np.sum(clean_mat)+nwords*csmooth)\n",
    "    x1=np.sum(toxic_mat,0)\n",
    "    x2=nword_toxic\n",
    "    return ptoxic,pword_toxic,pword_clean    \n",
    "\n",
    "ptox,pw_tox,pw_cln = cond_prob( X_train_counts, df_train['toxic'].values, csmooth=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def naive_bayes(mat,pword_tox,pword_cln,ptox):\n",
    "    \"\"\"Compute probability that a message \n",
    "    is toxic via naive_bayes estimate.\n",
    "    \"\"\"\n",
    "    #ptox_word = (pword_tox * p_tox)/(pword_cln*pcln + pword_tox * p_tox)\n",
    "    #Can use logs:  #Can just add the logs, and exponentiate at the end\n",
    "    #Compute log of conditional probability of p(toxic|word)\n",
    "    ##init version:\n",
    "    # pword=pword_tox*ptox/(pword_tox*ptox + pword_cln*(1-ptox))\n",
    "    # #log probability for toxic/clean comments\n",
    "    # log_Tword = np.log(pword)\n",
    "    # log_Cword = np.log(1-pword)    \n",
    "    # # #now accumulate probabilities by multiplying number of counts\n",
    "    # #per comment, with the weights per word\n",
    "    # log_Tscore = mat.dot(log_Tword.T)\n",
    "    # log_Cscore = mat.dot(log_Cword.T)\n",
    "    # pred=log_Tscore>log_Cscore\n",
    "    \n",
    "    # ##futzing version\n",
    "    pwordT=pword_tox#*ptox/(pword_tox*ptox + pword_cln*(1-ptox))    \n",
    "    pwordC=pword_cln#*(1-ptox)/(pword_tox*ptox + pword_cln*(1-ptox))\n",
    "\n",
    "    #log probability for toxic/clean comments\n",
    "    log_Tword = np.log(pwordT)\n",
    "    log_Cword = np.log(pwordC)\n",
    "    # #now accumulate probabilities by multiplying number of counts\n",
    "    #per comment, with the weights per word\n",
    "    msk=mat>0\n",
    "    # print(msk.shape,log_Tword.shape,log_Cword.shape)\n",
    "    # for i in msk.indices:\n",
    "    #     print('p(w,T),p(w,C)',pword_tox[0,i],pword_cln[0,i])        \n",
    "    #     print('p(w|T),p(w|C)',pwordT[0,i],pwordC[0,i])    \n",
    "    #     print('logs',log_Tword[0,i],log_Cword[0,i])\n",
    "    #     print('count',mat[0,i])        \n",
    "    log_Tscore = mat.dot(log_Tword.T)+np.log(ptox)\n",
    "    log_Cscore = mat.dot(log_Cword.T)+np.log(1-ptox)\n",
    "    pred=log_Tscore>log_Cscore    \n",
    "\n",
    "    #score=np.exp(log_score)\n",
    "    return pred,log_Tscore,log_Cscore,log_Tword,log_Cword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "actual=df_train['toxic'].values\n",
    "msk=actual\n",
    "Xtox = X_train_counts[msk,:]\n",
    "df_tox=df_train[msk]\n",
    "pred,logT,logC,log_Tword,log_Cword=naive_bayes(X_train_counts,pw_tox,pw_cln,ptox)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95692, 1) (95692, 1)\n",
      "True Positive 0.00896626677256197. False Positive 0.009196171048781508\n",
      "False Negative 0.0009300672992517661. True Negative 0.9809074948794048\n"
     ]
    }
   ],
   "source": [
    "def check_predictions(pred,actual):\n",
    "    actual=np.reshape(actual,(len(actual),1))\n",
    "    pred=np.reshape(pred,(len(actual),1))    \n",
    "    print(pred.shape,actual.shape)\n",
    "    tp = np.mean((pred==True)&(actual==True))\n",
    "    fp = np.mean((pred==True)&(actual==False))    \n",
    "    tn = np.mean((pred==False)&(actual==False))\n",
    "    fn = np.mean((pred==False)&(actual==True))            \n",
    "    scores=[tp,tn,fp,fn]\n",
    "    print(\"True Positive {}. False Positive {}\".format(tp,fp))\n",
    "    print(\"False Negative {}. True Negative {}\".format(fn,tn))    \n",
    "    return scores\n",
    "score_rates=check_predictions(pred,actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Look at the false negatives \n",
    "# df_fn=df_train[(pred==False)]\n",
    "# df_fn=df_fn[df_fn['toxic']==True]\n",
    "# df_fn[['comment_clean','mean_toxic','median_toxic']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So, this simple classifier has bad performance.  The rate of false negatives means we miss roughly half of toxic comments!  Roughly 1\\% of the data\n",
    "are \"toxic\" under the metric where the median toxicity score is -2.   It misses 3x as many toxic comments when feed toxic comments based on the median toxicity being -1.\n",
    "The false negatives in that larger seem to be more rules-lawyering, whinging about admnistration, and sidestepping filters. e.g. f:)u:)c:)k:).\n",
    "This is a bit harder for the classifier to find.\n",
    "\n",
    "Also length?  Can try a SVM, and then some dimensionality reduction word2vec, then neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB(alpha=0.01)\n",
    "nb.fit(X_train_counts,df_train['toxic'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95692, 1) (95692, 1)\n",
      "True Positive 0.00896626677256197. False Positive 0.009196171048781508\n",
      "False Negative 0.0009300672992517661. True Negative 0.9809074948794048\n"
     ]
    }
   ],
   "source": [
    "pred_nb=nb.predict(X_train_counts)\n",
    "nb_stats=check_predictions(pred_nb,actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Well, I must have an error in my Naive Bayes code.  I'm getting much worse results.  Have correct class probabilities, and conditional probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99010367  0.00989633]\n",
      "0.00989633407181 0.990103665928\n"
     ]
    }
   ],
   "source": [
    "#class priors agree\n",
    "print(np.exp(nb.class_log_prior_))\n",
    "print(ptox,1-ptox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-19.49909328 -13.79198301 -14.19578837 ..., -14.88397276 -14.88397276\n",
      "  -14.88397276]]\n",
      "[-19.49909328 -13.79198301 -14.19578837 ..., -14.88397276 -14.88397276\n",
      " -14.88397276]\n"
     ]
    }
   ],
   "source": [
    "#conditional probabilities agree, i.e.  log(P(w|T))\n",
    "[pw_cln2,pw_tox2]=nb.feature_log_prob_\n",
    "print(np.log(pw_cln))\n",
    "print(pw_cln2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#check computes probabilities for each class\n",
    "nb_logprob=np.matrix(nb.predict_log_proba(X_train_counts))\n",
    "nb_jll=np.matrix(nb._joint_log_likelihood(X_train_counts))\n",
    "# log_probabilities for each message\n",
    "nb_logC=nb_logprob[:,0]\n",
    "nb_logT=nb_logprob[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[   0.        , -152.61213392],\n        [   0.        , -121.75430671],\n        [   0.        , -691.48789889],\n        ..., \n        [   0.        , -997.78984736],\n        [   0.        , -136.79274693],\n        [   0.        , -157.51107803]])"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pred_nb=np.matrix(pred_nb).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0135330017138\n"
     ]
    }
   ],
   "source": [
    "msk=np.matrix((pred!=pred_nb))\n",
    "print(np.mean(msk))\n",
    "smsk = sparse.coo_matrix(msk)\n",
    "#print out to find some mismatched indices.\n",
    "#print(smsk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]] [[False]] False\n",
      "[[-0.01064289]] [[-4.5481796]] \n",
      "\n",
      "[[-0.02159582]] [[-9.16477778]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ind=575\n",
    "print(pred_nb[ind],pred[ind],actual[ind])\n",
    "print(nb_logC[ind],nb_logT[ind],\"\\n\")\n",
    "print(logC[ind],logT[ind],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00751187 -0.01408395]]\n",
      "  (0, 104335)\t1\n",
      "  (0, 116314)\t1\n"
     ]
    }
   ],
   "source": [
    "print(log_Cword[0,[104335,116314]])\n",
    "print(X_train_counts[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "In CS229, Andrew Ng's assignemnt sugest the SVM as a natural improvement over the Naive Bayes method.  Let's implement one of those.\n",
    "I'm going to update it to do batch gradient descent with sparse matrices.  The version I wrote initially was trash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-7bd16e246506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_counts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jonathan/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 random_seed)\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/jonathan/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m\"\"\"base matrix class for compressed row and column oriented matrices\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "svm=SVC(cache_size=500,verbose=True,class_weight={True:2,False:1})\n",
    "svm.fit(X_train_counts,actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9245"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nb.sum()\n",
    "actual=df_train['toxic'].values\n",
    "actual.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#define a cost function, check that we're minimizing it.\n",
    "#define the alternative cost function to be sure we'e also minimize that original choice.\n",
    "#check constraints are obeyed?\n",
    "def svm_cost(alpha,Kmat,cat,l):\n",
    "    m = Kmat.shape[0]\n",
    "    Ka = np.dot(Kmat,alpha);            \n",
    "    cost=0.5*l*np.dot( alpha, Ka)\n",
    "    yvec=(1-cat*Ka)/m\n",
    "    ymsk=yvec>0\n",
    "    cost+=np.sum(yvec*ymsk)\n",
    "    return cost                    \n",
    "\n",
    "#Compute Kernel Matrix, an m x m matrix\n",
    "#that effectively measures similarity between inputs.\n",
    "#each K_{ij} is the \"distance\" between the weighted inputs,\n",
    "# $x^{(i)}_k, $x^{(j)}_k$.\n",
    "# def kernel_matrix(x,tau):\n",
    "#     m=x.shape[0]\n",
    "#     x=(x>0).astype(int)\n",
    "#     K=np.zeros([m,m])\n",
    "#     for i in range(0,m):\n",
    "#         K[:,i]=np.exp(-np.sum((x-x[i])**2,1)/(2*tau**2));\n",
    "#     return K\n",
    "\n",
    "#Compute a column from the Kernel matrix.\n",
    "#Matrix is assumed to be [m,m], with vec\n",
    "#of length m.  Returns vector of length m.\n",
    "# def Kvec(mat,vec,tau):\n",
    "#     xarg=np.sum((mat-vec)**2,1)\n",
    "#     Kv=np.exp(-xarg/(2*tau**2));\n",
    "#     return Kv\n",
    "\n",
    "def Kbatch(mat,ind,norm2,tau):\n",
    "    \"\"\"Kbatch(mat,cvec,ind,norm2,tau)\n",
    "    Compute a batch of kernel matrix elements \n",
    "    Input: mat  - sparse matrix (nobs x nfeature)\n",
    "           ind - indices for that subset of rows (nbatch)\n",
    "           norm2 - column matrix with squared norm for each (nobs,1)\n",
    "    Return: Kvecs - nbatch x nobs subset of the full kernel matrix.\n",
    "    \"\"\"\n",
    "    nbatch=len(ind)\n",
    "    #extract chosen rows\n",
    "    cvec = mat[ind,:].T\n",
    "    #relying on numpy broadcasting to join (nobs,nbatch) + (nobs,1)\n",
    "    xarg=-2.0*mat.dot(cvec)+norm2\n",
    "    #further broadcasting: use a row-vector ind to make a row-vector\n",
    "    #of relevant norms.\n",
    "    #then broadcast again from (nobs,nbatch)+ (1,nbatch)\n",
    "    xarg+=norm2[ind].T\n",
    "    Kv=np.exp(-xarg/(2*tau**2));\n",
    "    #NOT TESTED YET!\n",
    "    return Kv\n",
    "\n",
    "#carry out update on parameters for given loss function for SVM,\n",
    "#given parameters, a row-vector of inputs K_i\n",
    "def svm_batchsgd_update(alpha,Kbatch,y,ind,rate,l):\n",
    "    \"\"\"svm_batchsgd_update\n",
    "    alpha  - nobs x 1 vector\n",
    "    Kbatch - nobs x Nbatch subset of Kernel matrix\n",
    "    y      - (1xNbatch) labels for inputs\n",
    "    ind    - (1xNbatch) indices for batch\n",
    "    \"\"\"\n",
    "    nobs = K_i.shape[0]\n",
    "    yK = np.multiply(y,Kbatch)   #nobs x Nbatch \n",
    "    yKa = np.dot(alpha.T,yK);\n",
    "    Kalpha = np.multiply(Kbatch,alpha[ind])\n",
    "    #da= (-y_i*K_i)*((1-y_i*Ka) >0)+m*l*K_i*alpha[ind];\n",
    "    da= (-yK)*((y*Ka)<-1)+nobs*l*Kalpha;\n",
    "    #sum all changes over columns\n",
    "    alpha=alpha-rate*np.sum(da,axis=1);\n",
    "    return alpha\n",
    "    \n",
    "#Fit SVM coefficients for spam with stochastic gradient descent.\n",
    "#use known categories in cat_vec, and word_matrix with nobs x nwords\n",
    "def svm_fit(word_mat,cat_vec,tau=8,Nbatch=100):\n",
    "    #just count whether word occurs.\n",
    "    new_mat=(word_mat>0).astype(int)\n",
    "    new_m\n",
    "    nobs,nword=new_mat.shape;\n",
    "    alpha=np.zeros((nobs,1))    #initialize parameters\n",
    "    alpha_tot=np.zeros((nobs,1))\n",
    "    niter=40*nobs;\n",
    "    l=1/(tau**2*nobs)\n",
    "\n",
    "    norm2=new_mat.multiply(new_mat).sum(axis=1)\n",
    "    #multiple iterations of stochastic gradient descent.\n",
    "    for t in range(0,niter):\n",
    "        indx=np.random.uniform(Nbatch,low=0,high=nobs).astype(int)\n",
    "        Kv = Kbatch(new_mat,indx,norm2,tau)\n",
    "        Kt=Kmat[indx,:]\n",
    "        yt=cat_vec[indx]\n",
    "        rate=np.sqrt(1.0/(t+1))\n",
    "        alpha=svm_sgd_update(alpha,Kt,yt,indx,rate,l)\n",
    "        alpha_tot=alpha_tot+alpha\n",
    "    alpha_tot=alpha_tot/niter\n",
    "    return alpha_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "norm2=X_train_counts.multiply(X_train_counts).sum(axis=1)\n",
    "ind=np.random.randint(size=100,low=0,high=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Kb=Kbatch(X_train_counts,ind,norm2,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95692, 100)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[5, 4],\n",
       "        [7, 6]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.matrix([[2],[4]])\n",
    "B = np.matrix([[3,0,5],[0,0,9]])\n",
    "Bs = sparse.csr_matrix(B)\n",
    "a+np.matrix([[3,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2],\n",
       "        [2],\n",
       "        [4],\n",
       "        [2]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind=[0,0,1,0]\n",
    "a[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "init_explore.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
