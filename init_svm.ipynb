{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "The one problem with the kernelized SVM is that it's training time scales as $O(n_{\\text{sample}}^\\alpha)$, with scaling exponent between 2 and 3.\n",
    "\n",
    "I've come across a couple approximate methods.  The first is a bagged model using an ensemble of SVM's based on subsets of the data. That leverages the existing (presumably smarter) scikit-learn code, in a way that could scale up.  Each classifier is then part of an ensemble, and we determine the class by majority vote. \n",
    "This in essence assumes that the Kernel matrix is block-diagonal, since this ensemble misses any correlations between the different subsets.\n",
    "One way would be to take multiple random batches of data.\n",
    "\n",
    "Or use an approximate kernel via Random Fourier Components.  The resulting SVM uses the linear library (but requires $N_{\\text{sample}}$ samples per Kernel estimate.)  This method can be applied to any method where the kernel function $K(x,y)$ has a known Fourier transform (which can be\n",
    "efficiently sampled from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_com=pd.read_csv('saved_dataframes/cleaned_comments.tsv.gzip',sep='\\t',compression='gzip')\n",
    "train_msk=df_com['split']=='train'\n",
    "df_train=df_com[train_msk]\n",
    "df_dev=df_com[df_com['split']=='dev']\n",
    "df_test=df_com[df_com['split']=='test']\n",
    "\n",
    "count_vect=CountVectorizer(stop_words='english',lowercase=True,strip_accents='unicode')\n",
    "tfidf_vect=TfidfVectorizer(stop_words='english',lowercase=True,strip_accents='unicode')\n",
    "X_train_counts=count_vect.fit_transform(df_train['comment_clean'])\n",
    "X_train_tfidf=tfidf_vect.fit_transform(df_train['comment_clean'])\n",
    "\n",
    "#do the same transformations using existing vocab built up in training.\n",
    "X_dev_tfidf=tfidf_vect.transform(df_dev['comment_clean'])\n",
    "X_test_tfidf=tfidf_vect.transform(df_test['comment_clean'])\n",
    "\n",
    "X_dev_counts=count_vect.transform(df_dev['comment_clean'])\n",
    "X_test_counts=count_vect.transform(df_test['comment_clean'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# SVM Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Since apparently the training time for a SVM goes as $O(n_{sample}^{3})$, maybe it is better to train an ensemble of SVMs.\n",
    "In which case the training time is $O(n_{sample}^{3}/n_{ensemble^{2}})$ for the ensemble.  Then evaluating the results typically takes $O(n_sample)$ for all of the ensemble together.  (This is something like making the crude assumption that the kernels are block-diagonal, once appropriately sorted).  If we repeat this for multiple such random splits we can extract different correlations.\n",
    "The final choice is based on take a majority vote.\n",
    "\n",
    "Like any good idea, this ideas has been had before.  A similar idea is available here:(https://stackoverflow.com/questions/31681373/making-svm-run-faster-in-python), which suggests\n",
    "using a BaggingClassifier to automate the whole process.  \n",
    "Of course, Random Forests are another option, with a similar goal.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#just use bagging classifier on the whole list of SVMs\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "nfeature,nobs=X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Try to determine parameters gamma/C via cross-validation.\n",
    "#Note that there is no need for explicit regularization?  Apparently in large dimensions, the parameters C/gamma (for penalty radius and width of basis function do a decent job in regularizing), since l1, l2 regularization don't work.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "ind_sub,Xsub,label_sub=get_subset(0.01,X_train_counts,actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#make the SVM model\n",
    "svm=SVC(cache_size=750,gamma=0.01,C=10,class_weight='balanced')\n",
    "#The bagging classifier of those\n",
    "ensemble_svm=BaggingClassifier(svm,n_estimators=10,\n",
    "bootstrap=False,n_jobs=3,max_samples=0.1,oob_score=False,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "frac_perc=0.2\n",
    "#svm=SVC(cache_size=1000,verbose=True,gamma=0.1,C=0.5,class_weight='balanced')\n",
    "indsub,Xsub,label_sub=get_subset(frac_perc,X_train_counts,df_train['toxic'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 62.2320671081543\n",
      "(15288, 1) (15288, 1)\n",
      "True Positive 0.03270538984824699. False Positive 0.0005232862375719519\n",
      "False Negative 0.06397174254317112. True Negative 0.9027995813710099\n",
      "Log-loss is 2.227579796059745\n",
      "AUROC is 0.6688578514324013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:   20.2s finished\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "#use the ravel for reshaping?\n",
    "ensemble_svm.fit(Xsub,label_sub.ravel())\n",
    "svm_pred=ensemble_svm.predict(Xsub)\n",
    "#test on a different subset of the training data\n",
    "t1=time.time()\n",
    "print('Time Elapsed:',t1-t0)\n",
    "svm_stats=check_predictions(svm_pred,label_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3821, 1) (3821, 1)\n",
      "True Positive 0.03245223763412719. False Positive 0.0010468463752944255\n",
      "False Negative 0.06411934048678357. True Negative 0.9023815755037948\n",
      "Log-loss is 2.25076119359395\n",
      "AUROC is 0.66744230594102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    4.5s finished\n"
     ]
    }
   ],
   "source": [
    "frac_perc=0.04\n",
    "#svm=SVC(cache_size=1000,verbose=True,gamma=0.1,C=0.5,class_weight='balanced')\n",
    "indsub2,Xsub2,label_sub2=get_subset(frac_perc,X_train_counts,df_train['toxic'].values)\n",
    "svm_pred2=ensemble_svm.predict(Xsub2)\n",
    "svm_stats2=check_predictions(svm_pred2,label_sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Use Cross-validation to split, estimate score.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gam_arr=np.logspace(-2,2,6)\n",
    "C_arr=np.logspace(-2,2,6)\n",
    "param_grid=dict(base_estimator__gamma=gam_arr,base_estimator__C=C_arr)\n",
    "\n",
    "svm=SVC(cache_size=500,gamma=0.01,C=10,class_weight='balanced')\n",
    "#The bagging classifier of those\n",
    "\n",
    "ensemble_svm=BaggingClassifier(svm,n_estimators=10,\n",
    "bootstrap=False,n_jobs=2,max_samples=0.1,oob_score=False,verbose=True)\n",
    "\n",
    "#Uses stratified k-fold cross-validation.\n",
    "gridsearch_svm=GridSearchCV(ensemble_svm,param_grid,error_score=0,scoring='neg_log_loss',cv=5)\n",
    "\n",
    "#Then do grid search over that.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "##So this search took around 5 hours on 2 cores, with 20% of data, 10 estimators.  \n",
    "#gridsearch_svm.fit(Xsub,label_sub.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  8.515379  ,   9.01231294,   9.75185003,   9.73938398,   9.98681965,\n",
       "         10.32953625,   9.1302866 ,   9.20638032,   9.61401176,   9.70504975,\n",
       "         10.125845  ,  10.38082843,   8.5658195 ,   9.51361198,   9.58338413,\n",
       "          9.42688198,   9.7426013 ,   9.23867021,   5.23752804,   8.05332527,\n",
       "          8.26427064,   8.61298461,   8.92178097,   9.07002459,   4.95735879,\n",
       "          7.89778571,   8.14328508,   8.49073753,   8.82482314,   8.98313236,\n",
       "          5.27298045,   7.23655725,   8.26355944,   8.421489  ,   8.68758707,\n",
       "          8.9933918 ]),\n",
       " 'mean_score_time': array([ 16.90008068,  18.05262084,  19.87818789,  20.06860175,  20.97318258,\n",
       "         21.40729494,  17.89313512,  18.53377829,  19.04816036,  19.9470829 ,\n",
       "         21.13045225,  21.46793203,  16.92121625,  19.20889707,  18.34303741,\n",
       "         19.25774665,  19.23158917,  17.89144721,   7.61561131,  13.21875992,\n",
       "         16.03910851,  16.0835259 ,  17.37367401,  17.5949316 ,   6.19260755,\n",
       "         12.71468387,  15.98310966,  16.0452239 ,  17.41438856,  17.49364271,\n",
       "          6.12942586,  11.16674943,  15.96487865,  16.28454676,  17.12438517,\n",
       "         17.5315721 ]),\n",
       " 'mean_test_score': array([ -0.71580878,  -0.70329975,  -0.64666623,  -0.84030266,  -0.8436247 ,\n",
       "         -0.84038816,  -1.89615752, -10.65392048,  -0.86358376,  -0.71580878,\n",
       "         -0.97884358,  -0.63625162,  -1.23701811,  -1.8471173 ,  -3.05546166,\n",
       "         -3.31240949,  -3.30719932,  -3.31077077,  -0.99229367,  -2.05492054,\n",
       "         -3.14768134,  -3.31234772,  -3.31077919,  -3.31777803,  -1.2057978 ,\n",
       "         -2.06745151,  -3.08448554,  -3.31420447,  -3.31414998,  -3.31603013,\n",
       "         -1.20315073,  -1.83690545,  -3.10696299,  -3.31607536,  -3.31253991,\n",
       "         -3.31597578]),\n",
       " 'mean_train_score': array([ -0.71581757,  -0.70356566,  -0.64669311,  -0.84031327,  -0.84363947,\n",
       "         -0.84029311,  -1.86699012, -10.45613367,  -0.82586368,  -0.71581757,\n",
       "         -0.9787932 ,  -0.63628528,  -0.93725732,  -0.92228325,  -1.19868935,\n",
       "         -1.27110322,  -1.30793762,  -1.28658017,  -0.42571015,  -0.80877355,\n",
       "         -1.21720545,  -1.26650219,  -1.26979203,  -1.29651541,  -0.50364364,\n",
       "         -0.8118258 ,  -1.17911359,  -1.28167681,  -1.28146482,  -1.28826001,\n",
       "         -0.50058809,  -0.72165193,  -1.2294766 ,  -1.27575567,  -1.26497872,\n",
       "         -1.30750424]),\n",
       " 'param_base_estimator__C': masked_array(data = [0.01 0.01 0.01 0.01 0.01 0.01 0.063095734448019331 0.063095734448019331\n",
       "  0.063095734448019331 0.063095734448019331 0.063095734448019331\n",
       "  0.063095734448019331 0.39810717055349731 0.39810717055349731\n",
       "  0.39810717055349731 0.39810717055349731 0.39810717055349731 0.39810717055349731\n",
       "  2.5118864315095824 2.5118864315095824 2.5118864315095824 2.5118864315095824\n",
       "  2.5118864315095824 2.5118864315095824 15.848931924611142 15.848931924611142\n",
       "  15.848931924611142 15.848931924611142 15.848931924611142 15.848931924611142\n",
       "  100.0 100.0 100.0 100.0 100.0 100.0],\n",
       "              mask = [False False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False False\n",
       "  False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_base_estimator__gamma': masked_array(data = [0.01 0.063095734448019331 0.39810717055349731 2.5118864315095824\n",
       "  15.848931924611142 100.0 0.01 0.063095734448019331 0.39810717055349731\n",
       "  2.5118864315095824 15.848931924611142 100.0 0.01 0.063095734448019331\n",
       "  0.39810717055349731 2.5118864315095824 15.848931924611142 100.0 0.01\n",
       "  0.063095734448019331 0.39810717055349731 2.5118864315095824 15.848931924611142\n",
       "  100.0 0.01 0.063095734448019331 0.39810717055349731 2.5118864315095824\n",
       "  15.848931924611142 100.0 0.01 0.063095734448019331 0.39810717055349731\n",
       "  2.5118864315095824 15.848931924611142 100.0],\n",
       "              mask = [False False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False False\n",
       "  False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'base_estimator__C': 0.01, 'base_estimator__gamma': 0.01},\n",
       "  {'base_estimator__C': 0.01, 'base_estimator__gamma': 0.063095734448019331},\n",
       "  {'base_estimator__C': 0.01, 'base_estimator__gamma': 0.39810717055349731},\n",
       "  {'base_estimator__C': 0.01, 'base_estimator__gamma': 2.5118864315095824},\n",
       "  {'base_estimator__C': 0.01, 'base_estimator__gamma': 15.848931924611142},\n",
       "  {'base_estimator__C': 0.01, 'base_estimator__gamma': 100.0},\n",
       "  {'base_estimator__C': 0.063095734448019331, 'base_estimator__gamma': 0.01},\n",
       "  {'base_estimator__C': 0.063095734448019331,\n",
       "   'base_estimator__gamma': 0.063095734448019331},\n",
       "  {'base_estimator__C': 0.063095734448019331,\n",
       "   'base_estimator__gamma': 0.39810717055349731},\n",
       "  {'base_estimator__C': 0.063095734448019331,\n",
       "   'base_estimator__gamma': 2.5118864315095824},\n",
       "  {'base_estimator__C': 0.063095734448019331,\n",
       "   'base_estimator__gamma': 15.848931924611142},\n",
       "  {'base_estimator__C': 0.063095734448019331, 'base_estimator__gamma': 100.0},\n",
       "  {'base_estimator__C': 0.39810717055349731, 'base_estimator__gamma': 0.01},\n",
       "  {'base_estimator__C': 0.39810717055349731,\n",
       "   'base_estimator__gamma': 0.063095734448019331},\n",
       "  {'base_estimator__C': 0.39810717055349731,\n",
       "   'base_estimator__gamma': 0.39810717055349731},\n",
       "  {'base_estimator__C': 0.39810717055349731,\n",
       "   'base_estimator__gamma': 2.5118864315095824},\n",
       "  {'base_estimator__C': 0.39810717055349731,\n",
       "   'base_estimator__gamma': 15.848931924611142},\n",
       "  {'base_estimator__C': 0.39810717055349731, 'base_estimator__gamma': 100.0},\n",
       "  {'base_estimator__C': 2.5118864315095824, 'base_estimator__gamma': 0.01},\n",
       "  {'base_estimator__C': 2.5118864315095824,\n",
       "   'base_estimator__gamma': 0.063095734448019331},\n",
       "  {'base_estimator__C': 2.5118864315095824,\n",
       "   'base_estimator__gamma': 0.39810717055349731},\n",
       "  {'base_estimator__C': 2.5118864315095824,\n",
       "   'base_estimator__gamma': 2.5118864315095824},\n",
       "  {'base_estimator__C': 2.5118864315095824,\n",
       "   'base_estimator__gamma': 15.848931924611142},\n",
       "  {'base_estimator__C': 2.5118864315095824, 'base_estimator__gamma': 100.0},\n",
       "  {'base_estimator__C': 15.848931924611142, 'base_estimator__gamma': 0.01},\n",
       "  {'base_estimator__C': 15.848931924611142,\n",
       "   'base_estimator__gamma': 0.063095734448019331},\n",
       "  {'base_estimator__C': 15.848931924611142,\n",
       "   'base_estimator__gamma': 0.39810717055349731},\n",
       "  {'base_estimator__C': 15.848931924611142,\n",
       "   'base_estimator__gamma': 2.5118864315095824},\n",
       "  {'base_estimator__C': 15.848931924611142,\n",
       "   'base_estimator__gamma': 15.848931924611142},\n",
       "  {'base_estimator__C': 15.848931924611142, 'base_estimator__gamma': 100.0},\n",
       "  {'base_estimator__C': 100.0, 'base_estimator__gamma': 0.01},\n",
       "  {'base_estimator__C': 100.0, 'base_estimator__gamma': 0.063095734448019331},\n",
       "  {'base_estimator__C': 100.0, 'base_estimator__gamma': 0.39810717055349731},\n",
       "  {'base_estimator__C': 100.0, 'base_estimator__gamma': 2.5118864315095824},\n",
       "  {'base_estimator__C': 100.0, 'base_estimator__gamma': 15.848931924611142},\n",
       "  {'base_estimator__C': 100.0, 'base_estimator__gamma': 100.0}],\n",
       " 'rank_test_score': array([ 5,  3,  2,  6,  8,  7, 17, 36,  9,  4, 10,  1, 14, 16, 20, 28, 24, 25,\n",
       "        11, 18, 23, 27, 26, 35, 13, 19, 21, 31, 30, 33, 12, 15, 22, 34, 29, 32], dtype=int32),\n",
       " 'split0_test_score': array([ -0.87704875,  -0.87704875,  -0.87704875,  -0.87704875,  -0.43867866,\n",
       "         -0.43867866,  -1.42500013, -11.3424326 ,  -0.36665192,  -0.87704875,\n",
       "         -1.12196909,  -0.87704875,  -1.37291082,  -1.81217138,  -3.03015315,\n",
       "         -3.31693458,  -3.30823517,  -3.30848105,  -1.03159586,  -2.00505149,\n",
       "         -3.15950878,  -3.31666734,  -3.31714965,  -3.30822867,  -1.22940648,\n",
       "         -2.09010226,  -3.06855658,  -3.31738608,  -3.31716978,  -3.3171467 ,\n",
       "         -1.26912281,  -1.79068715,  -3.05373122,  -3.31684865,  -3.32504735,\n",
       "         -3.30848105]),\n",
       " 'split0_train_score': array([ -0.87711549,  -0.87711549,  -0.87711549,  -0.87711549,  -0.4385392 ,\n",
       "         -0.4385392 ,  -1.39068737, -10.96370345,  -0.36254854,  -0.87711549,\n",
       "         -1.12210854,  -0.87711549,  -1.02908859,  -0.88602357,  -1.14068609,\n",
       "         -1.38664046,  -1.30489494,  -1.28670978,  -0.44422661,  -0.77495283,\n",
       "         -1.12382935,  -1.28540492,  -1.29352747,  -1.36786968,  -0.5139841 ,\n",
       "         -0.81635674,  -1.13929845,  -1.26598151,  -1.26098839,  -1.25747308,\n",
       "         -0.55341567,  -0.73058688,  -1.21429081,  -1.2405029 ,  -1.27568866,\n",
       "         -1.32256822]),\n",
       " 'split1_test_score': array([ -0.69314718,  -0.69314718,  -0.43867866,  -0.87704875,  -0.87704875,\n",
       "         -0.35731277,  -4.45995781, -10.86063741,  -0.32217813,  -0.69314718,\n",
       "         -0.69309949,  -0.87704875,  -1.27296641,  -2.24403555,  -3.11704334,\n",
       "         -3.3086941 ,  -3.30866236,  -3.30848553,  -1.02715101,  -2.08866793,\n",
       "         -3.17713868,  -3.30856048,  -3.30842268,  -3.31716759,  -1.13448077,\n",
       "         -2.05450971,  -3.15344822,  -3.30837917,  -3.30806006,  -3.30851279,\n",
       "         -1.18551875,  -1.88021637,  -3.13717043,  -3.30877289,  -3.30052203,\n",
       "         -3.31745715]),\n",
       " 'split1_train_score': array([ -0.69314718,  -0.69314718,  -0.4385392 ,  -0.87711549,  -0.87711549,\n",
       "         -0.3570846 ,  -4.48207223, -10.62419525,  -0.31421916,  -0.69314718,\n",
       "         -0.69308755,  -0.87711549,  -0.99328572,  -1.15203573,  -1.21720009,\n",
       "         -1.20289982,  -1.3104003 ,  -1.28868225,  -0.4477432 ,  -0.84190458,\n",
       "         -1.23011376,  -1.34231229,  -1.2909988 ,  -1.26584836,  -0.49661282,\n",
       "         -0.74434562,  -1.16849905,  -1.26571256,  -1.25284298,  -1.27270467,\n",
       "         -0.49722094,  -0.70184862,  -1.15518281,  -1.28024216,  -1.23578349,\n",
       "         -1.27753912]),\n",
       " 'split2_test_score': array([-0.69314718, -0.5540721 , -0.43847843, -0.69314718, -0.54997178,\n",
       "        -2.09045117, -1.08436048, -9.75059853, -0.69465067, -0.69314718,\n",
       "        -2.09045117, -0.43847843, -1.26271409, -1.7360863 , -3.0170738 ,\n",
       "        -3.3085045 , -3.29994389, -3.3005496 , -1.04085649, -2.03904439,\n",
       "        -3.09081128, -3.299612  , -3.30018689, -3.33459144, -1.14244727,\n",
       "        -2.0321922 , -3.03251709, -3.30892559, -3.30015607, -3.30898398,\n",
       "        -1.09518301, -1.86279079, -3.0830193 , -3.30934669, -3.30037236,\n",
       "        -3.30895316]),\n",
       " 'split2_train_score': array([-0.69314718, -0.55488216, -0.43858927, -0.69314718, -0.55002483,\n",
       "        -2.09016372, -1.10164482, -9.83339124, -0.69575575, -0.69314718,\n",
       "        -2.09016372, -0.43858927, -1.00924597, -0.8943078 , -1.20490656,\n",
       "        -1.33665106, -1.29788789, -1.31336584, -0.44267475, -0.84877256,\n",
       "        -1.21267506, -1.30038491, -1.29752614, -1.28344367, -0.48717521,\n",
       "        -0.82295263, -1.17283544, -1.26334477, -1.29925669, -1.27940845,\n",
       "        -0.50071869, -0.70404551, -1.24847786, -1.26466208, -1.22340563,\n",
       "        -1.26700167]),\n",
       " 'split3_test_score': array([-0.87713433, -0.69314718, -1.12214791, -0.87713433, -1.47556128,\n",
       "        -0.87713433, -0.98359049, -9.19306489, -2.61842949, -0.43849984,\n",
       "        -0.54998203, -0.54998203, -1.00203631, -1.63342622, -3.08733405,\n",
       "        -3.31840336, -3.30937037, -3.3183268 , -1.00720047, -2.03616286,\n",
       "        -3.13274428, -3.31831089, -3.3179003 , -3.31866626, -1.25011717,\n",
       "        -1.99356714, -3.04938641, -3.30922397, -3.30990513, -3.31840209,\n",
       "        -1.31131248, -1.78916568, -3.15849207, -3.31830345, -3.31816976,\n",
       "        -3.31788224]),\n",
       " 'split3_train_score': array([-0.87709409, -0.69314718, -1.12206383, -0.87709409, -1.47542371,\n",
       "        -0.87709409, -0.96288012, -9.33330586, -2.43887079, -0.43858391,\n",
       "        -0.55002226, -0.55002226, -0.7380188 , -0.82705989, -1.18183466,\n",
       "        -1.21570424, -1.30597833, -1.28831942, -0.44908856, -0.77410907,\n",
       "        -1.24539366, -1.21751727, -1.20827711, -1.28967043, -0.52795972,\n",
       "        -0.84506741, -1.20982213, -1.24630525, -1.32106713, -1.37197192,\n",
       "        -0.46413247, -0.77517203, -1.26626265, -1.28366249, -1.29995417,\n",
       "        -1.34432665]),\n",
       " 'split4_test_score': array([ -0.43849984,  -0.69903698,  -0.35702019,  -0.87713433,  -0.87713433,\n",
       "         -0.43849984,  -1.52699582, -12.12263678,  -0.31659629,  -0.87713433,\n",
       "         -0.43849984,  -0.43849984,  -1.27436626,  -1.80970666,  -3.025695  ,\n",
       "         -3.30951149,  -3.30978537,  -3.31801593,  -0.85461298,  -2.10568862,\n",
       "         -3.17819696,  -3.31859097,  -3.31023711,  -3.31023711,  -1.27257883,\n",
       "         -2.16689039,  -3.11850525,  -3.32711028,  -3.33546414,  -3.32711028,\n",
       "         -1.15461957,  -1.86166201,  -3.10242027,  -3.32711028,  -3.31859097,\n",
       "         -3.32711028]),\n",
       " 'split4_train_score': array([ -0.43858391,  -0.69953627,  -0.35715775,  -0.87709409,  -0.87709409,\n",
       "         -0.43858391,  -1.39766608, -11.52607258,  -0.31792415,  -0.87709409,\n",
       "         -0.43858391,  -0.43858391,  -0.9166475 ,  -0.85198923,  -1.24881935,\n",
       "         -1.21362053,  -1.32052661,  -1.25582358,  -0.34481763,  -0.80412873,\n",
       "         -1.27401541,  -1.18689153,  -1.25863062,  -1.27574489,  -0.49248634,\n",
       "         -0.83040662,  -1.20511289,  -1.36703995,  -1.27316892,  -1.25974191,\n",
       "         -0.48745267,  -0.6966066 ,  -1.26316889,  -1.3097087 ,  -1.29006167,\n",
       "         -1.32608552]),\n",
       " 'std_fit_time': array([ 0.25612311,  0.40797018,  0.01430292,  0.07180082,  0.05723591,\n",
       "         0.10841713,  0.28313762,  0.0727448 ,  0.31102707,  0.67346563,\n",
       "         0.07258312,  0.08912651,  0.08360285,  0.20985146,  0.66493143,\n",
       "         0.70834115,  1.03539217,  0.32378256,  0.17717752,  0.25480575,\n",
       "         0.10085472,  0.13068764,  0.16611329,  0.26060181,  0.31331754,\n",
       "         0.13475645,  0.09062662,  0.10021842,  0.15273362,  0.16846911,\n",
       "         0.29297818,  0.26581277,  0.1330419 ,  0.05575702,  0.09165637,\n",
       "         0.22922431]),\n",
       " 'std_score_time': array([ 0.728426  ,  1.39808469,  0.10727406,  0.1470467 ,  0.13147163,\n",
       "         0.14254813,  0.79870699,  0.18120523,  0.41152001,  0.49800089,\n",
       "         0.11621936,  0.18507796,  0.22293677,  0.25591367,  1.53217041,\n",
       "         1.93547984,  2.18060012,  0.26227302,  0.52834083,  0.25184484,\n",
       "         0.13871812,  0.0884704 ,  0.40891117,  0.37723907,  0.23371344,\n",
       "         0.20777505,  0.25067067,  0.09924382,  0.80812566,  0.23366787,\n",
       "         0.1324584 ,  0.52531133,  0.20586129,  0.14697613,  0.1738961 ,\n",
       "         0.20870189]),\n",
       " 'std_test_score': array([ 0.16120274,  0.10265459,  0.29986626,  0.07357775,  0.36103619,\n",
       "         0.65120121,  1.29804922,  1.06047258,  0.88842961,  0.16120274,\n",
       "         0.6022627 ,  0.20082187,  0.12411372,  0.20889512,  0.03951966,\n",
       "         0.00433248,  0.00366752,  0.00670071,  0.06970213,  0.03689794,\n",
       "         0.03285151,  0.00734476,  0.00647048,  0.00929427,  0.05671065,\n",
       "         0.0587655 ,  0.04494503,  0.00725603,  0.01195188,  0.00686706,\n",
       "         0.07793845,  0.03892116,  0.03740474,  0.00672181,  0.01017139,\n",
       "         0.00685968]),\n",
       " 'std_train_score': array([ 0.16119152,  0.10243012,  0.29984589,  0.07358304,  0.36102825,\n",
       "         0.65112177,  1.31825279,  0.78475365,  0.81892168,  0.16119152,\n",
       "         0.60215978,  0.200803  ,  0.10665391,  0.11738171,  0.03617396,\n",
       "         0.07572368,  0.00746513,  0.0182806 ,  0.04051238,  0.03182649,\n",
       "         0.05084917,  0.05655069,  0.03373705,  0.03655418,  0.01512167,\n",
       "         0.03506611,  0.02590871,  0.04330191,  0.02526741,  0.04263594,\n",
       "         0.02933823,  0.0292358 ,  0.04147194,  0.02280912,  0.03015899,\n",
       "         0.02988793])}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Useful for getting parameters of bagged classifier.\n",
    "#ensemble_svm.get_params()\n",
    "gridsearch_svm.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "scores=gridsearch_svm.cv_results_['mean_test_score'].reshape(len(gam_arr),len(C_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__C': 0.063095734448019331, 'base_estimator__gamma': 100.0}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gridsearch_svm.best_params_\n",
    "#Results:{'base_estimator__C': 0.063095734448019331, 'base_estimator__gamma': 100.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb1e17128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.exp(scores))\n",
    "plt.xticks(np.arange(len(gam_arr)),gam_arr,rotation=90)\n",
    "plt.yticks(np.arange(len(C_arr)),C_arr)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So this search took 5 hours or so (on 2 cores).  And suggests the two regions woth exploring are $C>1, \\gamma\\ll 1$, and $C<1,\\gamma\\gg 1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Randomized Fourier Features\n",
    "\n",
    "The Tensorflow documentation includes a great idea for extending Kernel machines: use an sinusoidal mapping from the original space to another linear space.  The mapping depends on a Gaussian random variable, so when we take expectation values over the Gaussian variable, the result\n",
    "of that expectation approximates the desired kernel.  Genius!\n",
    "Ideas here:(https://www.tensorflow.org/tutorials/kernel_methods,\n",
    "https://people.eecs.berkeley.edu/~brecht/papers/07.rah.rec.nips.pdf).\n",
    "See also scikit-learn's Kernel Approximations methods, which implement the RBF kernel described below. \n",
    "\n",
    "LinearSVMs work quickly, but their full kernel counterparts are slow to train, scaling as $O(n_{sample}^3)$.\n",
    "Instead, consider features like \n",
    "\\begin{equation}\n",
    "    z_{k}(\\mathbf{x})=\\cos(\\mathbf{\\omega}_{k}\\cdot\\mathbf{x}+b_{k}),\n",
    "\\end{equation}\n",
    "where $\\mathbf{x}\\in \\mathbb{R}^{d}, \\omega\\in \\mathbb{R}^{d},\\mathbf{b}_{k}\\in\\mathbb{R}$, and $\\omega_{k}$, is a random Gaussian vector drawn from\n",
    "\\begin{equation}\n",
    "    P(\\omega) = (2\\pi\\sigma^2)^{-d/2} \\exp\\left(-\\frac{\\mathbf{\\omega}^2}{2\\sigma^2}\\right),\n",
    "\\end{equation}\n",
    "and $b_{k}$ is a uniform random variable drawn from $[0,2\\pi)$.  Note that $z_{k}$ is a scalar.  But if we consider making $D$ draws of the random variables, then we can construct a vector $\\mathbf{z}(\\mathbf{x})=\\sqrt{\\frac{2}{D}}[z_{1},z_{2},\\ldots, z_{D}]$,\n",
    "\n",
    "The inner products on these new feature vectors for different input data are given y \n",
    "\\begin{equation}\n",
    "    \\mathbf{z}(\\mathbf{x})\\cdot\\mathbf{z}(\\mathbf{y})=\\frac{2}{D}\\sum_{k=1}^{D} \\cos(\\mathbf{\\omega}_{k}\\cdot\\mathbf{x}+b_{k})\\cos(\\mathbf{\\omega}_{k}\\cdot\\mathbf{y}+b_{k}).\n",
    "\\end{equation}\n",
    "This is essentially a Monte-Carlo estimate (with $D$ samples) of the probability distributions.  As $D\\rightarrow \\infty$, this converges to \n",
    "\\begin{align}\n",
    "    \\mathbf{z}(\\mathbf{x})\\cdot\\mathbf{z}(\\mathbf{y})&\\approx \\int d\\mathbf{\\omega}\\int db\\,P(\\omega)p(b)\n",
    "    2\\cos(\\mathbf{\\omega}\\cdot\\mathbf{x}+b)\\cos(\\mathbf{\\omega}\\cdot\\mathbf{y}+b)\\\\\n",
    "&=\\frac{1}{2\\pi}\\frac{1}{(2\\pi \\sigma^2)^{D/2}}\\int d\\mathbf{\\omega}\\int_0^{2\\pi} db\\,e^{-(\\mathbf{\\omega})^2/(2\\sigma^2)}\n",
    "    2\\cos(\\mathbf{\\omega}\\cdot\\mathbf{x}+b)\\cos(\\mathbf{\\omega}\\cdot\\mathbf{y}+b) \\\\\n",
    "&=\\frac{1}{2\\pi}\\frac{1}{(2\\pi \\sigma^2)^{D/2}}\\int d\\mathbf{\\omega}\\int_0^{2\\pi} db\\,e^{-(\\mathbf{\\omega})^2/(2\\sigma^2)}\n",
    "    \\bigg(\\cos[\\mathbf{\\omega}\\cdot(\\mathbf{x}+\\mathbf{y})+b]+\\cos[\\mathbf{\\omega}\\cdot(\\mathbf{x}-\\mathbf{y})]\\bigg),\n",
    "\\end{align}\n",
    "where we used a double-angle formula on the cosines.  The Gaussian and uniform integrals can be carried out, with the result\n",
    "\\begin{align}\n",
    "    \\mathbf{z}(\\mathbf{x})\\cdot\\mathbf{z}(\\mathbf{y})&\\approx \n",
    "&=\\,e^{-(\\mathbf{x-y})^2/(2\\sigma^2)}.\n",
    "\\end{align}\n",
    "The same idea can be extended for any $P(\\mathbf{\\omega})$ to get the desired kernel, provided it has a nice Fourier transform.\n",
    "\n",
    "One thing noted in the docs is that this works well for smooth data, but can require a lot of components if there is a significant random component, such as trying to detect fractal structures like forests in images.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 78.60097455978394\n",
      "(15288, 1) (15288, 1)\n",
      "True Positive 0.09641548927263213. False Positive 0.004120879120879121\n",
      "False Negative 0.00026164311878597594. True Negative 0.8992019884877027\n",
      "Log-loss is 0.15137025072587212\n",
      "AUROC is 0.9963658641979543\n"
     ]
    }
   ],
   "source": [
    "#Let's try to compare that with a full SVM on the same data.\n",
    "t0=time.time()\n",
    "full_svm=SVC(cache_size=1000,verbose=True,gamma=0.01,C=10,class_weight='balanced')\n",
    "full_svm.fit(Xsub,label_sub.ravel())\n",
    "full_svm_pred=full_svm.predict(Xsub)\n",
    "t1=time.time()\n",
    "print('Training time',t1-t0)\n",
    "svm_stats3=check_predictions(full_svm_pred,label_sub)"
   ]
  }
 ],
 "metadata": {
  "name": "bayes_svm.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
